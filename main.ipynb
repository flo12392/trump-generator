{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7591652797108776567\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3177234432\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 10581531973759208939\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 970, pci bus id: 0000:01:00.0, compute capability: 5.2\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.callbacks import LambdaCallback, ModelCheckpoint, EarlyStopping, CSVLogger\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, LSTM, Bidirectional, Embedding\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import load_model\n",
    "import keras.utils\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "import os\n",
    "import re\n",
    "import itertools\n",
    "import time\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "from src.read_data import read_trump_speeches\n",
    "from src.utils import print_tensorflow_devices\n",
    "from src.data_generator import DataGenerator\n",
    "from src.examples_generator_callback import ExamplesGeneratorCallback\n",
    "print_tensorflow_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "seq_len = 21 # includes next word.\n",
    "batch_size = 128\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 176350\n",
      "Test: 9282\n"
     ]
    }
   ],
   "source": [
    "speeches = read_trump_speeches('data/speeches.txt')\n",
    "words = np.unique(speeches)\n",
    "word_index = dict((c, i) for i, c in enumerate(words))\n",
    "index_word = dict((i, c) for i, c in enumerate(words))\n",
    "n_words = len(words)\n",
    "\n",
    "# Index the speeches, then create sentences of length 'seq_len' that we can train the RNN on.\n",
    "speeches_indexed = [word_index[x] for x in speeches]\n",
    "sentence_ranges = [range(i,i+seq_len) for i in range(0,len(speeches)-seq_len)]\n",
    "sentences = [[speeches[y] for y in x] for x in sentence_ranges]\n",
    "sentences_indexed = [[speeches_indexed[y] for y in x] for x in sentence_ranges]\n",
    "\n",
    "# Train-test split\n",
    "random.shuffle(sentences_indexed)\n",
    "train_split = int(0.95*len(sentences_indexed))\n",
    "sentences_indexed_train = sentences_indexed[:train_split]\n",
    "sentences_indexed_test = sentences_indexed[train_split:]\n",
    "print('Train: ' + str(len(sentences_indexed_train)))\n",
    "print('Test: ' +str(len(sentences_indexed_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model(version):\n",
    "     \n",
    "    # slightly bigger\n",
    "    if version == 1:\n",
    "        print('Build model...')\n",
    "        model = Sequential()\n",
    "        model.add(Bidirectional(LSTM(100, activation=\"relu\", return_sequences=True),input_shape=(seq_len-1, n_words)))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Bidirectional(LSTM(100, activation=\"relu\")))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(200, activation='relu'))\n",
    "        model.add(Dense(n_words, activation='softmax'))\n",
    "        return model\n",
    "    \n",
    "     # slightly bigger\n",
    "    if version == 2:\n",
    "        print('Build model...')\n",
    "        model = Sequential()\n",
    "        model.add(Bidirectional(LSTM(150, activation=\"relu\", return_sequences=True),input_shape=(seq_len-1, n_words)))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Bidirectional(LSTM(150, activation=\"relu\")))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(250, activation='relu'))\n",
    "        model.add(Dense(n_words, activation='softmax'))\n",
    "        return model\n",
    "    \n",
    "         # slightly bigger\n",
    "    if version == 3:\n",
    "        print('Build model...')\n",
    "        model = Sequential()\n",
    "        model.add(Bidirectional(LSTM(200, activation=\"relu\", return_sequences=True),input_shape=(seq_len-1, n_words)))\n",
    "        model.add(Dropout(0.4))\n",
    "        model.add(Bidirectional(LSTM(100, activation=\"relu\")))\n",
    "        model.add(Dropout(0.4))\n",
    "        model.add(Dense(150, activation='relu'))\n",
    "        model.add(Dropout(0.4))\n",
    "        model.add(Dense(150, activation='relu'))\n",
    "        model.add(Dense(n_words, activation='softmax'))\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Epoch 1/50\n",
      "1378/1378 [==============================] - 386s 280ms/step - loss: 5.8377 - acc: 0.0869 - val_loss: 5.4469 - val_acc: 0.1135\n",
      "Epoch 2/50\n",
      "1378/1378 [==============================] - 373s 271ms/step - loss: 5.1430 - acc: 0.1506 - val_loss: 4.9536 - val_acc: 0.1759\n",
      "Epoch 3/50\n",
      "1378/1378 [==============================] - 356s 258ms/step - loss: 4.7751 - acc: 0.1833 - val_loss: 4.7799 - val_acc: 0.1908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Florian\\Documents\\GIT\\trump-generator\\src\\utils.py:13: RuntimeWarning: divide by zero encountered in log\n",
      "  preds = np.log(preds) / temperature\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50\n",
      "1378/1378 [==============================] - 356s 258ms/step - loss: 4.5519 - acc: 0.1988 - val_loss: 4.6488 - val_acc: 0.2017\n",
      "Epoch 5/50\n",
      "1378/1378 [==============================] - 356s 258ms/step - loss: 4.3774 - acc: 0.2120 - val_loss: 4.5679 - val_acc: 0.2104\n",
      "Epoch 6/50\n",
      "1378/1378 [==============================] - 356s 258ms/step - loss: 4.2278 - acc: 0.2237 - val_loss: 4.5155 - val_acc: 0.2222\n",
      "Epoch 7/50\n",
      "1378/1378 [==============================] - 356s 258ms/step - loss: 4.0981 - acc: 0.2341 - val_loss: 4.4975 - val_acc: 0.2254\n",
      "Epoch 8/50\n",
      "1378/1378 [==============================] - 356s 259ms/step - loss: 3.9725 - acc: 0.2446 - val_loss: 4.5134 - val_acc: 0.2293\n",
      "Epoch 9/50\n",
      "1378/1378 [==============================] - 356s 258ms/step - loss: 3.8625 - acc: 0.2549 - val_loss: 4.5002 - val_acc: 0.2342\n",
      "Epoch 10/50\n",
      "1378/1378 [==============================] - 356s 258ms/step - loss: 3.7611 - acc: 0.2638 - val_loss: 4.5102 - val_acc: 0.2323\n",
      "Epoch 11/50\n",
      "1378/1378 [==============================] - 356s 258ms/step - loss: 3.6631 - acc: 0.2745 - val_loss: 4.5517 - val_acc: 0.2360\n",
      "Epoch 12/50\n",
      "1378/1378 [==============================] - 356s 258ms/step - loss: 3.5731 - acc: 0.2816 - val_loss: 4.5793 - val_acc: 0.2362\n",
      "Epoch 13/50\n",
      "1378/1378 [==============================] - 356s 258ms/step - loss: 3.4885 - acc: 0.2914 - val_loss: 4.5731 - val_acc: 0.2364\n",
      "Epoch 14/50\n",
      "1378/1378 [==============================] - 356s 258ms/step - loss: 3.4101 - acc: 0.2982 - val_loss: 4.6130 - val_acc: 0.2386\n",
      "Epoch 15/50\n",
      "1378/1378 [==============================] - 356s 258ms/step - loss: 3.3359 - acc: 0.3068 - val_loss: 4.6536 - val_acc: 0.2333\n",
      "Epoch 16/50\n",
      "1378/1378 [==============================] - 356s 258ms/step - loss: 3.2672 - acc: 0.3135 - val_loss: 4.6981 - val_acc: 0.2378\n",
      "Epoch 17/50\n",
      "1378/1378 [==============================] - 356s 258ms/step - loss: 3.1984 - acc: 0.3219 - val_loss: 4.7281 - val_acc: 0.2369\n",
      "Epoch 18/50\n",
      "1378/1378 [==============================] - 356s 258ms/step - loss: 3.1407 - acc: 0.3293 - val_loss: 4.7418 - val_acc: 0.2367\n",
      "Epoch 19/50\n",
      "1378/1378 [==============================] - 358s 259ms/step - loss: 3.0773 - acc: 0.3370 - val_loss: 4.8214 - val_acc: 0.2346\n",
      "Build model...\n",
      "Epoch 1/50\n",
      "1378/1378 [==============================] - 382s 277ms/step - loss: 5.7998 - acc: 0.0908 - val_loss: 5.2676 - val_acc: 0.1337\n",
      "Epoch 2/50\n",
      "1378/1378 [==============================] - 375s 272ms/step - loss: 5.0783 - acc: 0.1531 - val_loss: 4.9389 - val_acc: 0.1770\n",
      "Epoch 3/50\n",
      "1378/1378 [==============================] - 375s 272ms/step - loss: 4.7650 - acc: 0.1811 - val_loss: 4.7502 - val_acc: 0.1924\n",
      "Epoch 4/50\n",
      "1378/1378 [==============================] - 375s 272ms/step - loss: 4.5419 - acc: 0.2004 - val_loss: 4.6303 - val_acc: 0.2123\n",
      "Epoch 5/50\n",
      "1378/1378 [==============================] - 375s 272ms/step - loss: 4.3652 - acc: 0.2156 - val_loss: 4.5691 - val_acc: 0.2135\n",
      "Epoch 6/50\n",
      "1378/1378 [==============================] - 375s 272ms/step - loss: 4.2109 - acc: 0.2273 - val_loss: 4.5010 - val_acc: 0.2236\n",
      "Epoch 7/50\n",
      "1378/1378 [==============================] - 374s 272ms/step - loss: 4.0754 - acc: 0.2396 - val_loss: 4.4767 - val_acc: 0.2245\n",
      "Epoch 8/50\n",
      "1378/1378 [==============================] - 375s 272ms/step - loss: 3.9469 - acc: 0.2516 - val_loss: 4.4660 - val_acc: 0.2335\n",
      "Epoch 9/50\n",
      "1378/1378 [==============================] - 375s 272ms/step - loss: 3.8307 - acc: 0.2622 - val_loss: 4.4431 - val_acc: 0.2333\n",
      "Epoch 10/50\n",
      "1378/1378 [==============================] - 374s 272ms/step - loss: 3.7206 - acc: 0.2733 - val_loss: 4.4710 - val_acc: 0.2363\n",
      "Epoch 11/50\n",
      "1378/1378 [==============================] - 375s 272ms/step - loss: 3.6201 - acc: 0.2835 - val_loss: 4.4672 - val_acc: 0.2407\n",
      "Epoch 12/50\n",
      "1378/1378 [==============================] - 375s 272ms/step - loss: 3.5236 - acc: 0.2936 - val_loss: 4.5217 - val_acc: 0.2363\n",
      "Epoch 13/50\n",
      "1378/1378 [==============================] - 374s 272ms/step - loss: 3.4343 - acc: 0.3038 - val_loss: 4.5655 - val_acc: 0.2354\n",
      "Epoch 14/50\n",
      "1378/1378 [==============================] - 374s 272ms/step - loss: 3.3544 - acc: 0.3125 - val_loss: 4.5903 - val_acc: 0.2414\n",
      "Epoch 15/50\n",
      "1378/1378 [==============================] - 375s 272ms/step - loss: 3.2770 - acc: 0.3213 - val_loss: 4.6664 - val_acc: 0.2350\n",
      "Epoch 16/50\n",
      "1378/1378 [==============================] - 375s 272ms/step - loss: 3.2097 - acc: 0.3302 - val_loss: 4.6882 - val_acc: 0.2382\n",
      "Epoch 17/50\n",
      "1378/1378 [==============================] - 375s 272ms/step - loss: 3.1231 - acc: 0.3411 - val_loss: 4.7277 - val_acc: 0.2386\n",
      "Epoch 18/50\n",
      "1378/1378 [==============================] - 375s 272ms/step - loss: 3.0618 - acc: 0.3503 - val_loss: 4.7632 - val_acc: 0.2376\n",
      "Epoch 19/50\n",
      "1378/1378 [==============================] - 374s 272ms/step - loss: 2.9905 - acc: 0.3578 - val_loss: 4.8500 - val_acc: 0.2352\n",
      "Build model...\n",
      "Epoch 1/50\n",
      "1378/1378 [==============================] - 410s 298ms/step - loss: 5.7738 - acc: 0.0919 - val_loss: 5.3340 - val_acc: 0.1310\n",
      "Epoch 2/50\n",
      "1378/1378 [==============================] - 403s 292ms/step - loss: 5.1160 - acc: 0.1563 - val_loss: 4.9497 - val_acc: 0.1772\n",
      "Epoch 3/50\n",
      "1378/1378 [==============================] - 403s 292ms/step - loss: 4.7883 - acc: 0.1833 - val_loss: 4.7667 - val_acc: 0.1919\n",
      "Epoch 4/50\n",
      "1378/1378 [==============================] - 403s 292ms/step - loss: 4.5846 - acc: 0.1978 - val_loss: 4.6741 - val_acc: 0.2032\n",
      "Epoch 5/50\n",
      "1378/1378 [==============================] - 403s 292ms/step - loss: 4.4275 - acc: 0.2092 - val_loss: 4.5949 - val_acc: 0.2114\n",
      "Epoch 6/50\n",
      "1378/1378 [==============================] - 402s 292ms/step - loss: 4.2986 - acc: 0.2197 - val_loss: 4.5688 - val_acc: 0.2151\n",
      "Epoch 7/50\n",
      "1378/1378 [==============================] - 403s 292ms/step - loss: 4.1873 - acc: 0.2288 - val_loss: 4.5520 - val_acc: 0.2196\n",
      "Epoch 8/50\n",
      "1378/1378 [==============================] - 403s 292ms/step - loss: 4.0866 - acc: 0.2383 - val_loss: 4.5402 - val_acc: 0.2246\n",
      "Epoch 9/50\n",
      "1378/1378 [==============================] - 403s 292ms/step - loss: 3.9962 - acc: 0.2457 - val_loss: 4.5572 - val_acc: 0.2276\n",
      "Epoch 10/50\n",
      "1378/1378 [==============================] - 403s 292ms/step - loss: 3.9057 - acc: 0.2547 - val_loss: 4.5888 - val_acc: 0.2271\n",
      "Epoch 11/50\n",
      "1378/1378 [==============================] - 403s 292ms/step - loss: 3.8271 - acc: 0.2635 - val_loss: 4.6272 - val_acc: 0.2292\n",
      "Epoch 12/50\n",
      "1378/1378 [==============================] - 404s 293ms/step - loss: 3.7473 - acc: 0.2710 - val_loss: 4.6194 - val_acc: 0.2271\n",
      "Epoch 13/50\n",
      "1378/1378 [==============================] - 403s 292ms/step - loss: 3.6760 - acc: 0.2797 - val_loss: 4.6506 - val_acc: 0.2334\n",
      "Epoch 14/50\n",
      "1378/1378 [==============================] - 403s 292ms/step - loss: 3.6089 - acc: 0.2871 - val_loss: 4.6994 - val_acc: 0.2268\n",
      "Epoch 15/50\n",
      "1378/1378 [==============================] - 403s 292ms/step - loss: 3.5463 - acc: 0.2938 - val_loss: 4.7078 - val_acc: 0.2258\n",
      "Epoch 16/50\n",
      "1378/1378 [==============================] - 403s 292ms/step - loss: 3.5045 - acc: 0.2977 - val_loss: 4.7821 - val_acc: 0.2263\n",
      "Epoch 17/50\n",
      "1378/1378 [==============================] - 403s 292ms/step - loss: 3.4235 - acc: 0.3082 - val_loss: 4.7960 - val_acc: 0.2317\n",
      "Epoch 18/50\n",
      "1378/1378 [==============================] - 403s 292ms/step - loss: 3.3788 - acc: 0.3126 - val_loss: 4.8401 - val_acc: 0.2286\n"
     ]
    }
   ],
   "source": [
    "for version in [1,2,3]:\n",
    "\n",
    "    model_id = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    log_dir = 'log/' + model_id\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "\n",
    "    model_to_be_loaded = None\n",
    "    if model_to_be_loaded is not None:\n",
    "        model = load_model('models/' + model_to_be_loaded)\n",
    "    else:\n",
    "        model = get_model(version)\n",
    "\n",
    "    optimizer = Adam(lr=0.001)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    with open(log_dir + '/summary.txt','w') as fh:\n",
    "        # Pass the file handle in as a lambda function to make it callable\n",
    "        model.summary(print_fn=lambda x: fh.write(x + '\\n'))\n",
    "        \n",
    "    with open(log_dir + '/configuration.txt', 'w') as fout:\n",
    "        json.dump(model.get_config(), fout)\n",
    "\n",
    "    print_callback = ExamplesGeneratorCallback(sentences_indexed_test, index_word, log_dir + '/examples.txt', seq_len, n_words)\n",
    "    early_stopping = EarlyStopping(monitor='val_acc', patience=5)\n",
    "    csv_logger = CSVLogger(log_dir + '/loss_log.csv', append=True, separator=';')\n",
    "    callbacks_list = [print_callback, early_stopping, csv_logger]\n",
    "\n",
    "    history = model.fit_generator(DataGenerator(sentences_indexed_train, seq_len, n_words, batch_size),\n",
    "                        steps_per_epoch=int(len(sentences_indexed_train)/batch_size) + 1,\n",
    "                        epochs=epochs,\n",
    "                        callbacks=callbacks_list,\n",
    "                        validation_data=DataGenerator(sentences_indexed_test, seq_len, n_words, batch_size),\n",
    "                        validation_steps=int(len(sentences_indexed_test)/batch_size) + 1)\n",
    "\n",
    "    model.save(log_dir + '/' + time.strftime(\"%Y%m%d-%H%M%S\") + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model('models/LSTM256-Dr30-De100-acc0.45-valacc-0.25.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_model = '20180831-163242.h5'\n",
    "model = load_model('models/' + prediction_model)\n",
    "\n",
    "for i in range(10):\n",
    "    print('\\n ------------------------------------------------------------------- \\n\\n')\n",
    "        # Randomly pick a seed sequence\n",
    "    seed = (sentences_indexed)[np.random.randint(len(sentences_indexed))]\n",
    "    sentence = seed.copy()\n",
    "\n",
    "    for diversity in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "        sentence = seed\n",
    "\n",
    "        full_sentence = sentence.copy()\n",
    "\n",
    "        for i in range(250): \n",
    "            sentence = sentence[1:]\n",
    "            x_pred = np.zeros((1, seq_len - 1, n_words), dtype=np.bool)\n",
    "            for t, w in enumerate(sentence):\n",
    "                x_pred[0, t, w] = 1\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            sentence.append(next_index)\n",
    "            full_sentence.append(next_index)\n",
    "\n",
    "        full_sentence = [index_word[x] for x in full_sentence]\n",
    "        full_sentence = ' '.join(full_sentence)\n",
    "        print(full_sentence)\n",
    "        print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow2]",
   "language": "python",
   "name": "conda-env-tensorflow2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
