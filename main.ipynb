{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 14858044814870719890\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3177234432\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 708338030393306804\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 970, pci bus id: 0000:01:00.0, compute capability: 5.2\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.callbacks import LambdaCallback, ModelCheckpoint, EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, LSTM, Bidirectional, Embedding\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import keras.utils\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "import os\n",
    "import re\n",
    "import itertools\n",
    "from collections import Counter\n",
    "\n",
    "from src.read_data import read_trump_speeches\n",
    "from src.utils import print_tensorflow_devices\n",
    "from src.data_generator import DataGenerator\n",
    "print_tensorflow_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "seq_len = 21 # includes next word.\n",
    "\n",
    "# NN parameters\n",
    "batch_size = 128\n",
    "\n",
    "examples_file_loc = 'examples/examples.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches = read_trump_speeches('data/speeches.txt')\n",
    "words = np.unique(speeches)\n",
    "word_index = dict((c, i) for i, c in enumerate(words))\n",
    "index_word = dict((i, c) for i, c in enumerate(words))\n",
    "n_words = len(words)\n",
    "\n",
    "speeches_indexed = [word_index[x] for x in speeches]\n",
    "sentence_ranges = [range(i,i+seq_len) for i in range(0,len(speeches)-seq_len)]\n",
    "sentences = [[speeches[y] for y in x] for x in sentence_ranges]\n",
    "sentences_indexed = [[speeches_indexed[y] for y in x] for x in sentence_ranges]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function from keras-team/keras/blob/master/examples/lstm_text_generation.py\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "# Function modified from https://github.com/enriqueav/lstm_lyrics/blob/master/lstm_train.py\n",
    "def on_epoch_end(epoch, logs):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    examples_file.write('\\n----- Generating text after Epoch: %d\\n' % epoch)\n",
    "\n",
    "    # Randomly pick a seed sequence\n",
    "    seed = (sentences_indexed_test)[np.random.randint(len(sentences_indexed_test))]\n",
    "\n",
    "    for diversity in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "        sentence = seed\n",
    "        examples_file.write('\\n----- Diversity:' + str(diversity) + '\\n')\n",
    "        examples_file.write('----- Generating with seed:\\n\"' + ' '.join([index_word[x] for x in sentence]) + '\"\\n')\n",
    "\n",
    "        sentence = sentence.copy()\n",
    "        full_sentence = sentence.copy()\n",
    "        x_pred = np.zeros((batch_size, seq_len-1), dtype=np.int)\n",
    "        \n",
    "        for i in range(50):\n",
    "            x_pred[0,] = sentence[:-1]\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_word = next_index\n",
    "            sentence = sentence[1:]\n",
    "            sentence.append(next_word)\n",
    "            full_sentence.append(next_word)\n",
    "            \n",
    "        full_sentence = [index_word[x] for x in full_sentence]\n",
    "        examples_file.write(' '.join(full_sentence))\n",
    "    examples_file.write('\\n' + '='*80 + '\\n\\n')\n",
    "    examples_file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.shuffle(sentences_indexed)\n",
    "train_split = int(0.95*len(sentences_indexed))\n",
    "X = np.zeros((len(sentences_indexed), seq_len-1), dtype=np.int)\n",
    "y = np.zeros((len(sentences_indexed), n_words), dtype=np.bool)\n",
    "for i, sentence_idx in enumerate(sentences_indexed):\n",
    "    X[i,] = sentence_idx[:-1]\n",
    "    y[i, sentence_idx[-1]] = 1\n",
    "X_train, y_train = X[:train_split],y[:train_split]\n",
    "X_test, y_test = X[train_split:],y[train_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    print('Build model...')\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(n_words, 50, input_length=seq_len-1))\n",
    "    model.add(LSTM(100, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_words, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Epoch 1/100\n",
      " 29184/185632 [===>..........................] - ETA: 2:28 - loss: 6.0055 - acc: 0.0888"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "optimizer = Adam(lr=0.007)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=5)\n",
    "callbacks_list = [print_callback, early_stopping]\n",
    "\n",
    "examples_file = open(examples_file_loc, \"w\")\n",
    "\n",
    "model.fit(X,y,epochs=100, batch_size= 128)\n",
    "                    # callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow2]",
   "language": "python",
   "name": "conda-env-tensorflow2-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
