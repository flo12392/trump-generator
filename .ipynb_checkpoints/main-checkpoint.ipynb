{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 3091932945239389015\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3177234432\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 2065386910885991521\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 970, pci bus id: 0000:01:00.0, compute capability: 5.2\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.0 |Continuum Analytics, Inc.| (default, Dec  1 2015, 11:46:22) [MSC v.1900 64 bit (AMD64)]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Example script to generate text from a corpus of text\n",
    "--By word--\n",
    "It is recommended to run this script on GPU, as recurrent\n",
    "networks are quite computationally intensive.\n",
    "Based on\n",
    "https://github.com/keras-team/keras/blob/master/examples/lstm_text_generation.py\n",
    "20 epochs should be enough to get decent results.\n",
    "Uses data generator to avoid loading all the test set into memory.\n",
    "Saves the weights and model every epoch.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.callbacks import LambdaCallback, ModelCheckpoint, EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, LSTM, Bidirectional\n",
    "import keras.utils\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "import os\n",
    "import re\n",
    "import itertools\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "seq_len = 11 # includes next word.\n",
    "step = 1\n",
    "word_freq_threshold = 2\n",
    "\n",
    "# NN parameters\n",
    "batch_size = 64\n",
    "\n",
    "examples_file_loc = 'examples/examples.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read file\n",
    "file = open('data/speeches.txt', 'r',encoding='utf-8-sig') \n",
    "speeches = file.read()\n",
    "\n",
    "# Remove text between brackets, such as (inaudible) or (laughter)\n",
    "speeches = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", speeches)\n",
    "# Remove the speech introductions\n",
    "speeches = re.sub(r'SPEECH.+?\\n', '', speeches)\n",
    "# Replace multiple periods with a single one.\n",
    "speeches = re.sub('\\.+','. ',speeches)\n",
    "# different uses of this character\n",
    "speeches = re.sub('\\'','’',speeches)\n",
    "# Replace new lines with spaces\n",
    "speeches = re.sub('\\n',' ', speeches)\n",
    "\n",
    "# Treat the following interpunction characters as separate words, so we can generate them.\n",
    "speeches = re.sub('\\. ',' . ', speeches)\n",
    "speeches = re.sub(', ',' , ', speeches)\n",
    "speeches = re.sub('\\? ',' ? ', speeches)\n",
    "speeches = re.sub('! ',' ! ', speeches)\n",
    "speeches = re.sub('; ',' ; ', speeches)\n",
    "punc = '.,?!;'\n",
    "\n",
    "# Keep only this set of characters, replace multiple whitespace with single, and convert to lower case.\n",
    "speeches = re.sub('[^0-9a-zA-Z\\.,\\?!;’]+', ' ', speeches)\n",
    "speeches = re.sub('\\s+',' ', speeches)\n",
    "speeches = speeches.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = speeches.split(' ')\n",
    "counts = Counter(words)\n",
    "\n",
    "# Identify the foribdden words, i.e. words that occur less than a certain threshold.\n",
    "forbidden_words=[]\n",
    "for word in list(counts):\n",
    "    if counts[word] < word_freq_threshold:\n",
    "        forbidden_words.append(word)\n",
    "        \n",
    "# Find the indices of the forbidden words        \n",
    "forbidden_indices = [[i for i, x in enumerate(words) if x == f_word] for f_word in forbidden_words]\n",
    "forbidden_indices = list(itertools.chain.from_iterable(forbidden_indices))\n",
    "forbidden_indices.sort()\n",
    "\n",
    "# Now, create the ranges of words for the sentences. If a range contains one of the indices in\n",
    "# forbidden_indices, we omit it from the data.\n",
    "sentence_ranges = [range(i,i+seq_len-1) for i in range(0,len(words)-seq_len,step)]\n",
    "s = 0\n",
    "f = 0\n",
    "while (s < len(sentence_ranges)) & (f < len(forbidden_indices)):\n",
    "    if forbidden_indices[f] in sentence_ranges[s]:\n",
    "        sentence_ranges.pop(s)\n",
    "    else:\n",
    "        if max(sentence_ranges[s])>forbidden_indices[f]:\n",
    "            f+=1\n",
    "        else:\n",
    "            s+=1\n",
    "sentences = [[words[y] for y in x] for x in sentence_ranges]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = set(words)-set(forbidden_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_indices = dict((c, i) for i, c in enumerate(words))\n",
    "indices_word = dict((i, c) for i, c in enumerate(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentences: 3926\n",
      "Truncated sentences: 167188\n"
     ]
    }
   ],
   "source": [
    "print('Original sentences: ' + str(len([range(i,i+seq_len-1) for i in range(0,len(words)-seq_len,step)])))\n",
    "print('Truncated sentences: '+ str(len(sentences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# modified from https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly.html\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, sentences, word_indices, batch_size=32, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.sentences = sentences\n",
    "        self.word_indices = word_indices\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.sentences) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of sentences\n",
    "        sentences_temp = [self.sentences[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(sentences_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.sentences))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, sentences_temp):\n",
    "        'Generates data containing batch_size samples' \n",
    "        # Initialization\n",
    "        X = np.zeros((self.batch_size, seq_len-1, len(self.word_indices)), dtype=np.bool)\n",
    "        y = np.zeros((self.batch_size, len(self.word_indices)), dtype=np.bool)\n",
    "\n",
    "        # Generate data\n",
    "        for i, sentence in enumerate(sentences_temp):\n",
    "            # Generate X                       \n",
    "            for t, w in enumerate(sentence[:-1]):\n",
    "                X[i, t, self.word_indices[w]] = 1       \n",
    "                                           \n",
    "            y[i, self.word_indices[sentence[-1]]] = 1\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function from keras-team/keras/blob/master/examples/lstm_text_generation.py\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "# Function modified from https://github.com/enriqueav/lstm_lyrics/blob/master/lstm_train.py\n",
    "def on_epoch_end(epoch, logs):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    examples_file.write('\\n----- Generating text after Epoch: %d\\n' % epoch)\n",
    "\n",
    "    # Randomly pick a seed sequence\n",
    "    seed_index = np.random.randint(len(sentences_test))\n",
    "    seed = (sentences_test)[seed_index]\n",
    "\n",
    "    for diversity in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "        sentence = seed\n",
    "        examples_file.write('\\n----- Diversity:' + str(diversity) + '\\n')\n",
    "        examples_file.write('----- Generating with seed:\\n\"' + ' '.join(sentence) + '\"\\n')\n",
    "\n",
    "        sentence = sentence.copy()\n",
    "        full_sentence = sentence.copy()\n",
    "\n",
    "        for i in range(50):\n",
    "            x_pred = np.zeros((1, seq_len-1, len(word_indices)))\n",
    "            for t, word in enumerate(sentence):\n",
    "                x_pred[0, t, word_indices[word]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_word = indices_word[next_index]\n",
    "            sentence = sentence[1:]\n",
    "            sentence.append(next_word)\n",
    "            full_sentence.append(next_word)\n",
    "        examples_file.write(' '.join(full_sentence))\n",
    "    examples_file.write('\\n' + '='*80 + '\\n\\n')\n",
    "    examples_file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train test split\n",
    "random.shuffle(sentences)\n",
    "train_split = int(0.98*len(sentences))\n",
    "sentences_train = sentences[:train_split]\n",
    "sentences_test = sentences[train_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train test split\n",
    "random.shuffle(sentences)\n",
    "train_split = int(0.98*len(sentences))\n",
    "sentences_train = sentences[:train_split]\n",
    "sentences_test = sentences[train_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model(dropout=0.2):\n",
    "    print('Build model...')\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(128), input_shape=(seq_len-1, len(word_indices))))\n",
    "    if dropout > 0:\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(len(words)))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "[160983 139822   7253 ... 122265  35627  14083]\n",
      "[2833 2456 3016 ... 2504 1456 2335]\n",
      "Epoch 1/100\n",
      "2560/2613 [============================>.] - ETA: 3s - loss: 5.3425 - acc: 0.1300[ 75099  44764 128495 ...  87356  97115   1364]\n",
      "2612/2613 [============================>.] - ETA: 0s - loss: 5.3287 - acc: 0.1312[1412 1508  430 ... 2809  909 2427]\n",
      "2613/2613 [==============================] - 179s 69ms/step - loss: 5.3284 - acc: 0.1313 - val_loss: 4.8346 - val_acc: 0.1791\n",
      "Epoch 2/100\n",
      "2507/2613 [===========================>..] - ETA: 7s - loss: 4.5204 - acc: 0.2094[126057  75734 134156 ... 148790 142499 139124]\n",
      "2612/2613 [============================>.] - ETA: 0s - loss: 4.5056 - acc: 0.2104- ETA: 1s - loss: 4.50[ 892 2654 2098 ...  407 2276 2357]\n",
      "2613/2613 [==============================] - 176s 67ms/step - loss: 4.5054 - acc: 0.2104 - val_loss: 4.4661 - val_acc: 0.2121\n",
      "Epoch 3/100\n",
      "2454/2613 [===========================>..] - ETA: 10s - loss: 4.1344 - acc: 0.2409[ 94175  73353 117498 ...  70376  80522  34345]\n",
      "2612/2613 [============================>.] - ETA: 0s - loss: 4.1154 - acc: 0.2423[2535 1106 3214 ... 1740 3283 3102]\n",
      "2613/2613 [==============================] - 169s 65ms/step - loss: 4.1156 - acc: 0.2423 - val_loss: 4.2981 - val_acc: 0.2191\n",
      "Epoch 4/100\n",
      "2401/2613 [==========================>...] - ETA: 13s - loss: 3.8355 - acc: 0.2677[160175 135146 109041 ...  90750  24430  83015]\n",
      "2613/2613 [==============================] - 168s 64ms/step - loss: 3.8104 - acc: 0.2704 - val_loss: 4.1830 - val_acc: 0.2398\n",
      "[1992 2757  961 ... 2942 3128 2500]\n",
      "Epoch 5/100\n",
      "2346/2613 [=========================>....] - ETA: 17s - loss: 3.5825 - acc: 0.2939[ 19698 139675 124827 ... 141501 135644 123480]\n",
      "2613/2613 [==============================] - 169s 65ms/step - loss: 3.5508 - acc: 0.2970 - val_loss: 4.1349 - val_acc: 0.2551\n",
      "[ 959  737 2278 ...  705 2676 2399]\n",
      "Epoch 6/100\n",
      "2295/2613 [=========================>....] - ETA: 20s - loss: 3.3548 - acc: 0.3211[162070  30890  11437 ...  94332  56568  87057]\n",
      "2613/2613 [==============================] - 169s 64ms/step - loss: 3.3189 - acc: 0.3257 - val_loss: 4.1320 - val_acc: 0.2593\n",
      "[ 806 2438 3218 ...  631 2394 1401]\n",
      "Epoch 7/100\n",
      "2242/2613 [========================>.....] - ETA: 23s - loss: 3.1452 - acc: 0.3466[ 66581   3733 125044 ...  59490 149229 128737]\n",
      "2613/2613 [==============================] - 168s 64ms/step - loss: 3.1023 - acc: 0.3528 - val_loss: 4.1357 - val_acc: 0.2632\n",
      "[ 130 3273  931 ...  982 1775 1119]\n",
      "Epoch 8/100\n",
      "2188/2613 [========================>.....] - ETA: 26s - loss: 2.9525 - acc: 0.3722[ 15941  67479 135618 ...   3960 104891 124853]\n",
      "2613/2613 [==============================] - 167s 64ms/step - loss: 2.9010 - acc: 0.3802 - val_loss: 4.1622 - val_acc: 0.2665\n",
      "[2853 2689 2354 ... 1562 2441 3292]\n",
      "Epoch 9/100\n",
      "2136/2613 [=======================>......] - ETA: 30s - loss: 2.7758 - acc: 0.3992[112649 119102  41678 ...  78567  19348 135373]\n",
      "2613/2613 [==============================] - 168s 64ms/step - loss: 2.7177 - acc: 0.4090 - val_loss: 4.2055 - val_acc: 0.2623\n",
      "[1972 1947 2383 ... 1564 2782 2078]\n",
      "Epoch 10/100\n",
      "2082/2613 [======================>.......] - ETA: 33s - loss: 2.6064 - acc: 0.4257[ 95531 110292 131420 ... 137039  77088 107615]\n",
      "2613/2613 [==============================] - 168s 64ms/step - loss: 2.5420 - acc: 0.4369 - val_loss: 4.2786 - val_acc: 0.2623\n",
      "[ 223 1678 3260 ... 1911 2542  738]\n",
      "Epoch 11/100\n",
      "2030/2613 [======================>.......] - ETA: 37s - loss: 2.4479 - acc: 0.4514[ 89701 142673  93664 ...  66444 119744 122763]\n",
      "2613/2613 [==============================] - 168s 64ms/step - loss: 2.3819 - acc: 0.4638 - val_loss: 4.3170 - val_acc: 0.2668\n",
      "[2819 2365  650 ...  131 2756 2628]\n",
      "Epoch 12/100\n",
      "1977/2613 [=====================>........] - ETA: 40s - loss: 2.2924 - acc: 0.4768[115966 123152 136429 ... 117638  45144  35050]\n",
      "2613/2613 [==============================] - 168s 64ms/step - loss: 2.2236 - acc: 0.4901 - val_loss: 4.3946 - val_acc: 0.2668\n",
      "\n",
      "Epoch 13/100\n",
      "1924/2613 [=====================>........] - ETA: 44s - loss: 2.1568 - acc: 0.5031[ 60422 119133  65895 ...  73331  58659  38103]\n",
      "2613/2613 [==============================] - 171s 66ms/step - loss: 2.0837 - acc: 0.5182 - val_loss: 4.4699 - val_acc: 0.2659\n",
      "[1128 1691 2029 ... 1187 1141 1273]\n",
      "Epoch 14/100\n",
      "1871/2613 [====================>.........] - ETA: 47s - loss: 2.0165 - acc: 0.5279[132329 120204 134435 ... 102350  80127  14559]\n",
      "2613/2613 [==============================] - 170s 65ms/step - loss: 1.9371 - acc: 0.5451 - val_loss: 4.5891 - val_acc: 0.2647\n",
      "[1673 1106  438 ...  643 1358 1305]\n",
      "Epoch 15/100\n",
      "1818/2613 [===================>..........] - ETA: 51s - loss: 1.9032 - acc: 0.5508[ 29434 151100 105394 ...  56930 137503 127694]\n",
      "2612/2613 [============================>.] - ETA: 0s - loss: 1.8211 - acc: 0.5684[2872 2875 1077 ... 2914  665  290]\n",
      "2613/2613 [==============================] - 170s 65ms/step - loss: 1.8210 - acc: 0.5684 - val_loss: 4.6485 - val_acc: 0.2602\n",
      "Epoch 16/100\n",
      "1765/2613 [===================>..........] - ETA: 54s - loss: 1.7836 - acc: 0.5744 E[ 80071 138478  93144 ...  70371  48809 126058]\n",
      "2613/2613 [==============================] - 170s 65ms/step - loss: 1.7047 - acc: 0.5916 - val_loss: 4.7359 - val_acc: 0.2548\n",
      "[ 759 2832 2318 ... 2864  584 3309]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x218fca069b0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=5)\n",
    "callbacks_list = [print_callback, early_stopping]\n",
    "\n",
    "examples_file = open(examples_file_loc, \"w\")\n",
    "\n",
    "model.fit_generator(DataGenerator(sentences_train, word_indices, batch_size),\n",
    "                    steps_per_epoch=int(len(sentences)/batch_size) + 1,\n",
    "                    epochs=100,\n",
    "                    callbacks=callbacks_list,\n",
    "                    validation_data=DataGenerator(sentences_test, word_indices, batch_size),\n",
    "                    validation_steps=int(len(sentences_test)/batch_size) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow2]",
   "language": "python",
   "name": "conda-env-tensorflow2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
